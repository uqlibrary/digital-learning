{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVLTl0KlTb94"
      },
      "source": [
        "This script will check the urls in a column of a csv file. It will assign a different status based on the HTTP code returned when checking each url e.g. 200 will return that the link is \"Definitely Working\".\n",
        "\n",
        "It requires that your CSV file has a column named \"URL\" or \"Primary Web Address\" (if you would like it to check for columns with different labels let Kia know and they can update this)\n",
        "\n",
        "For Links that do not respond, the script will retry them 3 times with 4-8 seconds in between each retry.\n",
        "\n",
        "Some URLs such a government urls will not make any response when queried. The script will note these urls, it is likely that they have extra security features enabled.\n",
        "\n",
        "Some urls will return inconsistent responses in which case they will be noted as requiring manual checking.\n",
        "\n",
        "It will also note urls that prompt an automatic download, as well as urls that directly lead to pdfs.\n",
        "\n",
        "To update:\n",
        "\n",
        "\n",
        "*   Multiple Links in same column - Done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTc5xTYl4SZZ"
      },
      "outputs": [],
      "source": [
        "# This installs the packages needed\n",
        "!pip install aiohttp nest_asyncio pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXCLTFpC5ESn"
      },
      "outputs": [],
      "source": [
        "# This imports the packages into the environment\n",
        "import pandas as pd\n",
        "import aiohttp\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "import random\n",
        "from google.colab import files\n",
        "\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5OPNMNw5KHr"
      },
      "outputs": [],
      "source": [
        "# This is for uploading your CSV file. After you run you should be able to choose a file to upload. Right now only upload a CSV that has a column with the heading URL, it will check that column's urls\n",
        "uploaded = files.upload()\n",
        "df = pd.read_csv(next(iter(uploaded)))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Ez4afsuhqj2"
      },
      "outputs": [],
      "source": [
        "# Determine which column to use for URLs\n",
        "url_column = 'URL' if 'URL' in df.columns else 'Primary Web Address'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMks1mc0hxRl"
      },
      "outputs": [],
      "source": [
        "# Drop rows where the URL column is missing or NaN\n",
        "df = df.dropna(subset=[url_column])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9eCLNixkIIS"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "# Use regex to split only on \"; \" (semicolon followed by a space)\n",
        "df[url_column] = df[url_column].astype(str)\n",
        "df = df.assign(**{url_column: df[url_column].apply(lambda x: re.split(r';\\s+', x))})\n",
        "df = df.explode(url_column)\n",
        "df[url_column] = df[url_column].str.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o811DIfbG1bW"
      },
      "outputs": [],
      "source": [
        "# This function is for doing retries with some time in between each retry. It's currently set to 2 retries max with 2 seconds in between. The wait time will exponentially increase with each retry maxing out at 30 seconds.\n",
        "# Keep the number of retries at 2 or 3 for speedier results, I'm not sure if there'd be much benefit after that many retries\n",
        "async def fetch_with_retries(session, url, headers, proxy=None, max_retries=2):\n",
        "    timeout = aiohttp.ClientTimeout(total=30)\n",
        "    connector = aiohttp.TCPConnector(limit=30)\n",
        "    session = aiohttp.ClientSession(connector=connector)\n",
        "\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            async with session.get(url, headers=headers, proxy=proxy, allow_redirects=True, timeout=timeout) as response:\n",
        "                return response\n",
        "        except Exception as e:\n",
        "            if attempt < max_retries - 1:\n",
        "                wait_time = 6 ** attempt\n",
        "                print(f\"Attempt {attempt+1} failed for {url}. Retrying in {wait_time}s...\")\n",
        "                await asyncio.sleep(wait_time)\n",
        "            else:\n",
        "                print(f\"All retries failed for {url}: {type(e).__name__} - {e}\")\n",
        "                return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxsZdOa65OIu"
      },
      "outputs": [],
      "source": [
        "# This is the main function for returning the results in the file. It shows what error codes will return what result as well as ignores entries without a URL. It also mimics a real browser a bit with the headers defined near the top.\n",
        "async def check_with_aiohttp(session, url, proxy=None):\n",
        "    if not isinstance(url, str) or url.strip() == \"\":\n",
        "        return (\"No URL\", None, None, None, None, None)\n",
        "\n",
        "    headers = {\n",
        "        \"User-Agent\": (\n",
        "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
        "            \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
        "            \"Chrome/120.0.0.0 Safari/537.36\"\n",
        "        ),\n",
        "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
        "        \"Accept-Language\": \"en-US,en;q=0.5\",\n",
        "        \"Referer\": \"https://www.google.com\",\n",
        "        \"Connection\": \"keep-alive\",\n",
        "        \"Upgrade-Insecure-Requests\": \"1\"\n",
        "    }\n",
        "\n",
        "    response = await fetch_with_retries(session, url, headers, proxy)\n",
        "    if response:\n",
        "        status = response.status\n",
        "        redirects = len(response.history)\n",
        "        final_url = str(response.url)\n",
        "        content_type = response.headers.get(\"Content-Type\", \"\").lower()\n",
        "\n",
        "# Detect if it's a PDF\n",
        "        is_pdf = (\n",
        "            \"application/pdf\" in content_type or\n",
        "            final_url.lower().endswith(\".pdf\") or\n",
        "            \"pdf/\" in final_url.lower() or\n",
        "            \"/pdfdirect/\" in final_url.lower()\n",
        "        )\n",
        "        file_download = \"Yes\" if \"application/pdf\" in content_type or \"application/octet-stream\" in content_type else \"No\"\n",
        "        pdf_flag = \"Direct PDF\" if is_pdf else \"No\"\n",
        "        status_label = \"\"\n",
        "\n",
        "        if status == 200:\n",
        "            status_label = \"Definitely Working\"\n",
        "        elif status in [201, 202, 203]:\n",
        "            status_label = \"Likely Working\"\n",
        "        elif status in [301, 302]:\n",
        "            status_label = \"Likely Working (Redirect)\"\n",
        "        elif status in [404, 410]:\n",
        "            status_label = \"Definitely Broken\"\n",
        "        elif status in [403, 400]:\n",
        "            status_label = \"Requires Manual Check (Request Blocked)\"\n",
        "        else:\n",
        "            status_label = \"Likely Broken\"\n",
        "\n",
        "\n",
        "        if is_pdf:\n",
        "              status_label += \" (Direct PDF)\"\n",
        "\n",
        "        return (status_label, status, redirects, final_url, file_download, pdf_flag)\n",
        "\n",
        "    return (\"No Response (Likely Government or PQ URL)\", None, None, None, \"Unknown\", \"Unknown\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55obwchI5WQH"
      },
      "outputs": [],
      "source": [
        "#This is the main function that will begin the checking. This will take a while depending on the file size\n",
        "async def main(proxy_url=None):\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        results = []\n",
        "        for url in df[url_column]:\n",
        "            if isinstance(url, str) and any(domain in url for domain in [\"proquest.com\", \"resolver.library.uq\", \"ebookcentral.proquest\"]):\n",
        "                delay = random.randint(3, 5)\n",
        "                print(f\"Delaying {delay}s before checking: {url}\")\n",
        "                await asyncio.sleep(delay)\n",
        "\n",
        "            result = await check_with_aiohttp(session, url, proxy=proxy_url)\n",
        "            results.append(result)\n",
        "\n",
        "        df['Link Status'], df['HTTP Status Code'], df['Redirect Count'], df['Final URL'], df['File Download'], df['PDF Detected'] = zip(*results)\n",
        "\n",
        "await main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "mwMwrV2N5bcU",
        "outputId": "cdd5ba1c-9fd4-42ff-a6dc-47cee5cf927f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c98fbbd7-a34b-4706-b3e9-fa6de0390e1b\", \"output.csv\", 222578)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Use this to download the final CSV file\n",
        "df.head()\n",
        "df.to_csv(\"output.csv\", index=False)\n",
        "files.download(\"output.csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}